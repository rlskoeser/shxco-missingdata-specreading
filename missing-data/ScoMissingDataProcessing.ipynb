{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlskoeser/shxco-missingdata-specreading/blob/main/missing-data/Sco_prophet_missingdata_weekly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# S&Co Missing Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0fqvVhOWAtc"
      },
      "source": [
        "## Setup Libraries and Load S&Co Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import timedelta, datetime, date\n",
        "from datetimerange import DateTimeRange\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import altair as alt\n",
        "alt.data_transformers.disable_max_rows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TTtLzB3bV98E"
      },
      "outputs": [],
      "source": [
        "# use v1.2 datasets; load from our repo for convenience\n",
        "csv_urls = {\n",
        "    # official published versions \n",
        "    'members': 'https://raw.githubusercontent.com/rlskoeser/shxco-missingdata-specreading/main/data/source-data/SCoData_members_v1.2_2022-01.csv',\n",
        "    'books': 'https://raw.githubusercontent.com/rlskoeser/shxco-missingdata-specreading/main/data/source-data/SCoData_books_v1.2_2022-01.csv',\n",
        "    'events': 'https://raw.githubusercontent.com/rlskoeser/shxco-missingdata-specreading/main/data/source-data/SCoData_events_v1.2_2022-01.csv',\n",
        "\n",
        "    # project-specific data\n",
        "    'partial_borrowers': 'https://raw.githubusercontent.com/rlskoeser/shxco-missingdata-specreading/main/data/partial_borrowers_collapsed.csv',\n",
        "    'borrow_overrides': 'https://raw.githubusercontent.com/rlskoeser/shxco-missingdata-specreading/main/data/long_borrow_overrides.csv'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "64ShIITCWMml"
      },
      "outputs": [],
      "source": [
        "# load events\n",
        "events_df = pd.read_csv(csv_urls['events'], low_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl2LP4O3Wdl-"
      },
      "source": [
        "## Prepare logbook event data\n",
        "\n",
        "Logbooks are one of the primary sources of data for the S&Co Project, and detail the membership, renewal, and reimbursement activities. You can read more about them on the Project website [https://shakespeareandco.princeton.edu/sources/logbooks/](https://shakespeareandco.princeton.edu/sources/logbooks/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m56KXvskWQG3"
      },
      "outputs": [],
      "source": [
        "# identify to logbook events\n",
        "\n",
        "logbook_events_df = events_df[events_df.source_type.str.contains('Logbook')][[\n",
        "   'event_type', 'start_date', 'end_date', 'subscription_purchase_date',\n",
        "   'member_uris', 'member_names',\n",
        "   'subscription_duration', 'subscription_duration_days',\n",
        "   'subscription_volumes', 'subscription_category',\n",
        "   'source_type'\n",
        "]]\n",
        "\n",
        "# May need to add format=\"mixed\" depending on platform\n",
        "logbook_events_df['start_date'] = pd.to_datetime(logbook_events_df['start_date'])\n",
        "logbook_events_df['subscription_purchase_date'] = pd.to_datetime(logbook_events_df['subscription_purchase_date'])\n",
        "logbook_events_df['logbook_date'] = logbook_events_df.apply(lambda row: row.subscription_purchase_date if pd.notna(row.subscription_purchase_date) else row.start_date, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def earliest_date(row):\n",
        "  # earliest date is the start date, subscription purchase date, or end date\n",
        "  dates = [val for val in [row.start_date, row.subscription_purchase_date, row.end_date] if not pd.isna(val)]\n",
        "  if dates:\n",
        "    return min(dates)\n",
        "\n",
        "membership_events = events_df[events_df.event_type.isin(['Renewal', 'Subscription', 'Reimbursement' ,'Supplement', 'Separate Payment'])]\n",
        "nonlogbook_membership_events = membership_events[~membership_events.source_type.str.contains('Logbook')]\n",
        "membership_events['earliest_date'] = membership_events.apply(earliest_date, axis=1)\n",
        "membership_events['date'] = pd.to_datetime(membership_events['earliest_date'], errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJvQjbumWlpw"
      },
      "source": [
        "## Calculate logbook gaps\n",
        "\n",
        "While much of the membership data is consistent, there are periods where there are gaps in the data, largely for archival reasons. We have calculated these gaps and now can explore their distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "agOGR_ElWjoM"
      },
      "outputs": [],
      "source": [
        "response = requests.get('https://raw.githubusercontent.com/rlskoeser/shxco-missingdata-specreading/main/data/logbook-dates.json')\n",
        "logbook_dates = response.json()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pQJ6YQ62WoQt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 6 large gaps in the logbooks\n",
            "\tJanuary 01 1928 to February 29 1928 (59 days)\n",
            "\tJanuary 03 1930 to June 01 1930 (149 days)\n",
            "\tAugust 01 1930 to December 31 1930 (152 days)\n",
            "\tFebruary 17 1931 to September 25 1932 (586 days)\n",
            "\tJanuary 01 1937 to February 16 1938 (411 days)\n",
            "\tMay 06 1938 to October 20 1938 (167 days)\n",
            "\n",
            "The 5 small gaps in the logbooks that will be skipped\n",
            "\tOctober 30 1927 to November 01 1927 (2 days)\n",
            "\tFebruary 07 1934 to February 08 1934 (1 day)\n",
            "\tJanuary 01 1935 to January 11 1935 (10 days)\n",
            "\tDecember 29 1935 to January 01 1936 (3 days)\n",
            "\tAugust 29 1939 to September 12 1939 (14 days)\n"
          ]
        }
      ],
      "source": [
        "# don't consider gaps shorter than 15 days\n",
        "MIN_GAP_DAYS = 15\n",
        "\n",
        "logbook_gaps = []\n",
        "skipped_gaps = []\n",
        "\n",
        "oneday = timedelta(days=1)\n",
        "\n",
        "\n",
        "for i in range(len(logbook_dates) - 1):\n",
        "  # gaps are between the logbook dates, so gap start is end of the first\n",
        "  # and gap end is the start of the next\n",
        "\n",
        "  # gap start and end dates are now included in the range instead of bounds outside the range\n",
        "  gap_start = pd.to_datetime(logbook_dates[i]['endDate']) + oneday\n",
        "  gap_end = pd.to_datetime(logbook_dates[i+1]['startDate']) - oneday\n",
        "  interval = { 'start': gap_start, 'end': gap_end, 'days': (gap_end - gap_start).days }\n",
        "\n",
        "  if interval['days'] > MIN_GAP_DAYS:\n",
        "      logbook_gaps.append(interval) \n",
        "  elif interval['days'] > 0:  # ignore 0 and -1 duration \"gaps\"!\n",
        "     skipped_gaps.append(interval)\n",
        "\n",
        "\n",
        "print(f\"The {len(logbook_gaps)} large gaps in the logbooks\")\n",
        "for interval in logbook_gaps:\n",
        "    print(f\"\\t{interval['start'].strftime('%B %d %Y')} to {interval['end'].strftime('%B %d %Y')} ({interval['days']} days)\")\n",
        "\n",
        "print(f\"\\nThe {len(skipped_gaps)} small gaps in the logbooks that will be skipped\")\n",
        "for interval in skipped_gaps:\n",
        "    print(f\"\\t{interval['start'].strftime('%B %d %Y')} to {interval['end'].strftime('%B %d %Y')} ({interval['days']} day{'s' if interval['days'] != 1 else ''})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sxTPcZrvWqaf"
      },
      "outputs": [],
      "source": [
        "# get logbook event data *except* for during gaps\n",
        "# â€” v1.2 dataset has 9 stray events in these gaps; 8 misattributed to logbook source, one documented in a later logbook\n",
        "\n",
        "logbook_events_nogaps = logbook_events_df.copy()\n",
        "\n",
        "for i, gap in enumerate(logbook_gaps):\n",
        "  gap_start = gap['start']\n",
        "  gap_end = gap['end']\n",
        "  logbook_events_nogaps = logbook_events_nogaps[~((logbook_events_nogaps.logbook_date >= gap_start) & (logbook_events_nogaps.logbook_date <= gap_end))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYeKEEsmbZgs"
      },
      "source": [
        "# Missing membership events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqw-LgEnXAYm"
      },
      "source": [
        "## Logbook / membership events by week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KAcTsL5vW_k1"
      },
      "outputs": [],
      "source": [
        "logbooks_weekly_count = logbook_events_nogaps.groupby([pd.Grouper(key='logbook_date', freq='W')])['event_type'].count().reset_index()\n",
        "logbooks_weekly_count.rename(columns={'event_type': 'total'}, inplace=True)\n",
        "\n",
        "logbook_gaps_df = pd.DataFrame(logbook_gaps)\n",
        "logbook_gaps_df['gap_label'] = logbook_gaps_df.apply(lambda row: '%s to %s (%d days)' % (row.start.date().isoformat(), row.end.date().isoformat(), row.days), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkKXkkmyblNg"
      },
      "source": [
        "# missing members"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weK7qMg3bpsn"
      },
      "source": [
        "## member data setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ajxiPtVbbrYM"
      },
      "outputs": [],
      "source": [
        "# split multiple members for shared accounts in events\n",
        "events_df[\n",
        "    [\"first_member_uri\", \"second_member_uri\"]\n",
        "] = events_df.member_uris.str.split(\";\", expand=True)\n",
        "\n",
        "# working with the first member for now...\n",
        "# generate short ids equivalent to those in member and book dataframes\n",
        "events_df[\"member_id\"] = events_df.first_member_uri.apply(\n",
        "    lambda x: x.split(\"/\")[-2]\n",
        ")\n",
        "events_df[\"item_id\"] = events_df.item_uri.apply(\n",
        "    lambda x: x.split(\"/\")[-2] if pd.notna(x) else None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hB9Eyv_zbsAZ",
        "outputId": "dd3580ca-0cdf-4be4-d2dc-223cd45b4945"
      },
      "outputs": [],
      "source": [
        "# looking at all the data, what is the first event for each member?\n",
        "member_dates = events_df.copy()\n",
        "\n",
        "# make sure each event has an earliest known date\n",
        "def earliest_date(row):\n",
        "  dates = [val for val in [row.start_date, row.subscription_purchase_date, row.end_date] if not pd.isna(val)]\n",
        "  if dates:\n",
        "    return min(dates)     \n",
        "\n",
        "member_dates['earliest_date'] = member_dates.apply(earliest_date, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZNHH-MZdb0M9",
        "outputId": "8def6469-5f19-4451-fa00-7d80dbcbef0f"
      },
      "outputs": [],
      "source": [
        "# convert earliest date to datetime; convert partially known dates to -01-01  for now\n",
        "member_dates['date'] = pd.to_datetime(member_dates['earliest_date'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kFm-Wz3Db2ZO",
        "outputId": "ebb23308-8574-4c62-b6fd-61db6dd7cf4f"
      },
      "outputs": [],
      "source": [
        "# limit to the fields we want, drop unknown dates\n",
        "members_added = member_dates[['event_type', 'member_id', 'date', 'source_type']].dropna(subset=['date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "euyH1cMJb4m6"
      },
      "outputs": [],
      "source": [
        "members_added = members_added[members_added['date'] < datetime(1942, 1, 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "epSau6p6b57F",
        "outputId": "21d0e0b7-e56e-46e1-c44a-87830a1b298e"
      },
      "outputs": [],
      "source": [
        "# limit to member uri and date; then group by member and get the first date\n",
        "members_grouped = members_added[[\"member_id\", \"date\"]].groupby(\"member_id\")\n",
        "members_first_dates = members_grouped.first().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "sa8I_pM6b9Ik",
        "outputId": "f3c99173-f772-4ba7-b469-81cdc6efe172"
      },
      "outputs": [],
      "source": [
        "newmember_yearly_count = members_first_dates.groupby([pd.Grouper(key='date', freq='Y')])['member_id'].count().reset_index()\n",
        "newmember_yearly_count.rename(columns={'member_id': 'total'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "D6mfwrCPd3mX",
        "outputId": "20a82ad0-902a-41ad-8cd8-77354eda8ea6"
      },
      "outputs": [],
      "source": [
        "# group again but report on source and event type;\n",
        "# customize sorting to order so subscriptions will show up first\n",
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "# main order we care about is subscription first; other order matters less; reimbursement would be expected last\n",
        "event_type = CategoricalDtype(categories=[\"Subscription\", \"Renewal\", \"Separate Payment\", \"Borrow\", \"Purchase\", \"Supplement\", \"Request\", \"Gift\", \"Crossed out\", \"Reimbursement\"], ordered=True)\n",
        "# copy member data frame, and convert event type to our new categorical type\n",
        "member_events = members_added.copy()\n",
        "\n",
        "member_events['event_type'] = member_events.event_type.astype(event_type)\n",
        "\n",
        "# sort by date, then sort by event type so if there are any same-day events,\n",
        "# subscription should always be first\n",
        "member_events = member_events.sort_values(by=['date', 'event_type'])\n",
        "\n",
        "members_first_events = member_events.groupby(\"member_id\").first().reset_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g5qiZdPfxcw"
      },
      "source": [
        "### new members added, logbooks only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "v2TdH1c7flRM",
        "outputId": "bd3f0254-9452-45ae-e152-ed2748446915"
      },
      "outputs": [],
      "source": [
        "# get first events for each member from logbooks only\n",
        "\n",
        "# go back to member events, limit to logbook events, then group and get first event\n",
        "logbook_first_events = member_events[member_events.source_type.str.contains('Logbook')].groupby(\"member_id\").first().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "u6a8b7M7f5BA",
        "outputId": "cd5f4023-7d11-4f7e-96b4-bc340cfb4f1c"
      },
      "outputs": [],
      "source": [
        "# get new member yearly count for logbook-sourced events only \n",
        "logbook_newmembers_by_year = logbook_first_events.groupby([pd.Grouper(key='date', freq='Y')])['member_id'].count().reset_index()\n",
        "logbook_newmembers_by_year.rename(columns={'member_id': 'total'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXXFQFq717xN"
      },
      "source": [
        "### aggregate by month instead of year\n",
        "\n",
        "confusing because totals and graphs in the dataset essay are monthly, it looks wrong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5ljzELOa14d0",
        "outputId": "58763f1c-307f-426f-ebca-db5b7ab72def"
      },
      "outputs": [],
      "source": [
        "# get new member monthly count for logbook-sourced events only \n",
        "logbook_newmembers_by_month = logbook_first_events.groupby([pd.Grouper(key='date', freq='M')])['member_id'].count().reset_index()\n",
        "logbook_newmembers_by_month.rename(columns={'member_id': 'total'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "syv9G50s4Lhx",
        "outputId": "de191b88-5cf9-40c7-f80c-54f2d717ce88"
      },
      "outputs": [],
      "source": [
        "newmember_monthly_count = members_first_dates.groupby([pd.Grouper(key='date', freq='M')])['member_id'].count().reset_index()\n",
        "newmember_monthly_count.rename(columns={'member_id': 'total'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Qdv8ushqog"
      },
      "source": [
        "### members only documented in address books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6h0xuJMgrMN",
        "outputId": "93098760-39e5-45bb-f7a1-7863a9eef6ba"
      },
      "outputs": [],
      "source": [
        "# what about members we _only_ know about from the address books?\n",
        "\n",
        "# any member with at least one event in the logbooks\n",
        "logbook_members = member_events[member_events.source_type.str.contains('Logbook')].member_id.unique()\n",
        "# any member with at least one event on a card\n",
        "lending_card_members = member_events[member_events.source_type.str.contains('Lending Library Card')].member_id.unique()\n",
        "# any member with at least one event from an address book\n",
        "addressbook_members = member_events[member_events.source_type.str.contains('Address Book')].member_id.unique()\n",
        "\n",
        "# get a list of address-book-only members \n",
        "address_book_only_members = set(member_events.member_id.unique()) - set(logbook_members) - set(lending_card_members)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AlCf_ejuhuqf",
        "outputId": "d1d738f8-3d58-4780-92b0-222e375f903c"
      },
      "outputs": [],
      "source": [
        "# get date added for address-only members\n",
        "\n",
        "addressbook_first_events = member_events[member_events.member_id.isin(address_book_only_members)].groupby(\"member_id\").first().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "jJHzsYbGhwYC",
        "outputId": "fb5dd7ab-dc56-42a4-a8e5-5c7966e51416"
      },
      "outputs": [],
      "source": [
        "# get new member yearly count for addressbook-only members events only \n",
        "addressbook_newmembers_by_year = addressbook_first_events.groupby([pd.Grouper(key='date', freq='Y')])['member_id'].count().reset_index()\n",
        "addressbook_newmembers_by_year.rename(columns={'member_id': 'total'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx-4waGYjpuq"
      },
      "source": [
        "### members only documented on lending cards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T2SqEltjr-y",
        "outputId": "e7b744fe-48bb-4f7a-d13a-89ef3974cd98"
      },
      "outputs": [],
      "source": [
        "# do we have any lending-card only members?\n",
        "\n",
        "# get a list of address-book-only members \n",
        "lending_card_only_members = set(member_events.member_id.unique()) - set(logbook_members) - set(addressbook_members)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Qu1LQ6Yrj8XK",
        "outputId": "8765260b-3fa2-4324-fe3d-c045c42ce817"
      },
      "outputs": [],
      "source": [
        "# card-only member first events\n",
        "cardonly_first_events = member_events[member_events.member_id.isin(lending_card_only_members)].groupby(\"member_id\").first().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "mTneVD8jnYhZ",
        "outputId": "d037b0c0-a619-416b-c8fa-4261d3a699fb"
      },
      "outputs": [],
      "source": [
        "# get new member yearly count for lending card-only members\n",
        "cardonly_newmembers_by_year = cardonly_first_events.groupby([pd.Grouper(key='date', freq='Y')])['member_id'].count().reset_index()\n",
        "cardonly_newmembers_by_year.rename(columns={'member_id': 'total'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7jqUbnzqCPo"
      },
      "source": [
        "### other members"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmrLDmIopu5-",
        "outputId": "1f389c69-a855-4343-ef16-40fdc57b21f1"
      },
      "outputs": [],
      "source": [
        "# get all other members so we can generate stacked area chart properly\n",
        "\n",
        "other_members = set(member_events.member_id.unique()) - set(lending_card_only_members) - set(address_book_only_members)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "b9tBCfgEqDI6",
        "outputId": "33557483-a778-4ec5-8745-02afe1f6c039"
      },
      "outputs": [],
      "source": [
        "# other member first events\n",
        "other_member_first_events = member_events[member_events.member_id.isin(other_members)].groupby(\"member_id\").first().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "-Ky_B4KpqKlq",
        "outputId": "d875b9eb-fa15-4aab-edcc-a339bf382db5"
      },
      "outputs": [],
      "source": [
        "# new member yearly count \n",
        "other_newmembers_by_year = other_member_first_events.groupby([pd.Grouper(key='date', freq='Y')])['member_id'].count().reset_index()\n",
        "other_newmembers_by_year.rename(columns={'member_id': 'total'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kWEyWUVDh1eo",
        "outputId": "021e5927-acb4-4b6d-f825-c8bcaa0054e8"
      },
      "outputs": [],
      "source": [
        "# plot all three sets of new members together\n",
        "\n",
        "# combine into a single df for plotting with altair\n",
        "\n",
        "def combine_newmember_counts():\n",
        "  # new_member_counts = newmember_yearly_count.copy()\n",
        "  # new_member_counts['series'] = 'all events'\n",
        "\n",
        "  # FIXME: this is not plotting the same thing as the others!\n",
        "  # logbook_newmembers = logbook_newmembers_by_year.copy()\n",
        "  # logbook_newmembers['series'] = 'logbook events only'\n",
        "\n",
        "  other_newmembers = other_newmembers_by_year.copy()\n",
        "  other_newmembers['series'] = 'all other members'\n",
        "\n",
        "  addressbook_newmembers = addressbook_newmembers_by_year.copy()\n",
        "  addressbook_newmembers['series'] = 'addressbook-only members'\n",
        "  \n",
        "  card_newmembers = cardonly_newmembers_by_year.copy()\n",
        "  card_newmembers['series'] = 'card-only members'\n",
        "  \n",
        "  # combined_new_member_counts_df = pd.concat([new_member_counts, logbook_newmembers, addressbook_newmembers])\n",
        "  combined_new_member_counts_df = pd.concat([other_newmembers, addressbook_newmembers, card_newmembers])\n",
        "\n",
        "  return combined_new_member_counts_df\n",
        "\n",
        "combine_newmember_counts_df = combine_newmember_counts()\n",
        "\n",
        "\n",
        "\n",
        "# # clear from any previous run\n",
        "# plt.clf()\n",
        "# # setup shared axis\n",
        "# fig, ax = plt.subplots(figsize=(20, 5))\n",
        "\n",
        "# sns.lineplot(data=newmember_yearly_count, x='date', y='total', label='new members (all events)')\n",
        "# sns.lineplot(data=logbook_newmembers_by_year, x='date', y='total', label='new members (logbook events only)')\n",
        "# sns.lineplot(data=addressbook_newmembers_by_year, x='date', y='total', label='new members (addressbook-only members)')\n",
        "\n",
        "# for i, gap in enumerate(logbook_gaps): \n",
        "#   gap_start = pd.to_datetime(gap['start'])\n",
        "#   gap_end = pd.to_datetime(gap['end'])\n",
        "#   ax.axvspan(gap_start, gap_end, color=\"gray\", alpha=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXY35YhM6TN-"
      },
      "source": [
        "### aggregate new members from source by month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-7lo3xNF6Kpi",
        "outputId": "d821535d-a868-48e9-c16f-49cb70331fcd"
      },
      "outputs": [],
      "source": [
        "# get new member monthly count for addressbook-only members events only \n",
        "addressbook_newmembers_by_month = addressbook_first_events.groupby([pd.Grouper(key='date', freq='M')])['member_id'].count().reset_index()\n",
        "addressbook_newmembers_by_month.rename(columns={'member_id': 'total'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9d6k_na56dGC",
        "outputId": "d6f97208-f4ff-44de-8bd1-3d502a985441"
      },
      "outputs": [],
      "source": [
        "# get new member monthly count for lending card-only members\n",
        "cardonly_newmembers_by_month = cardonly_first_events.groupby([pd.Grouper(key='date', freq='M')])['member_id'].count().reset_index()\n",
        "cardonly_newmembers_by_month.rename(columns={'member_id': 'total'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BIi9O5Dw6iel",
        "outputId": "9fdb8826-dc21-42d2-c7fe-c8d79f77b38b"
      },
      "outputs": [],
      "source": [
        "# new member monthly count \n",
        "other_newmembers_by_month = other_member_first_events.groupby([pd.Grouper(key='date', freq='M')])['member_id'].count().reset_index()\n",
        "other_newmembers_by_month.rename(columns={'member_id': 'total'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "u_5quG0C6tV0",
        "outputId": "977b3e7c-854c-4a56-f673-059f826a908d"
      },
      "outputs": [],
      "source": [
        "# combine into a single df for plotting with altair\n",
        "\n",
        "def combine_newmember_monthly_counts():\n",
        "  # new_member_counts = newmember_yearly_count.copy()\n",
        "  # new_member_counts['series'] = 'all events'\n",
        "\n",
        "  # FIXME: this is not plotting the same thing as the others!\n",
        "  # logbook_newmembers = logbook_newmembers_by_year.copy()\n",
        "  # logbook_newmembers['series'] = 'logbook events only'\n",
        "\n",
        "  other_newmembers = other_newmembers_by_month.copy()\n",
        "  other_newmembers['series'] = 'all other members'\n",
        "\n",
        "  addressbook_newmembers = addressbook_newmembers_by_month.copy()\n",
        "  addressbook_newmembers['series'] = 'addressbook-only members'\n",
        "  \n",
        "  card_newmembers = cardonly_newmembers_by_month.copy()\n",
        "  card_newmembers['series'] = 'card-only members'\n",
        "  \n",
        "  # combined_new_member_counts_df = pd.concat([new_member_counts, logbook_newmembers, addressbook_newmembers])\n",
        "  combined_new_member_counts_df = pd.concat([other_newmembers, addressbook_newmembers, card_newmembers])\n",
        "\n",
        "  return combined_new_member_counts_df\n",
        "\n",
        "combine_newmember_monthly_counts_df = combine_newmember_monthly_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCTEL6z0vIxv"
      },
      "source": [
        "## new members by first subscription"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Rll16Vg5qlMx",
        "outputId": "428cd713-d2ea-4672-d2a1-792877a4f810"
      },
      "outputs": [],
      "source": [
        "# to model properly, we only expect membership to start with a subscription\n",
        "# include renewals, since sometimes they were written down for each other\n",
        "\n",
        "# go back to member events, limit to logbooks AND by event type, then group and get first event for each member\n",
        "subscription_first_events = member_events[member_events.source_type.str.contains('Logbook') & member_events.event_type.isin(['Subscription', 'Renewal'])].groupby(\"member_id\").first().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVh7S0Fu5RNo",
        "outputId": "6cdc049c-ca9a-47d5-e263-d63910197dcd"
      },
      "outputs": [],
      "source": [
        "# exclude from gaps, just in case\n",
        "\n",
        "subscription_first_events_nogaps = subscription_first_events.copy()\n",
        "\n",
        "for i, gap in enumerate(logbook_gaps):\n",
        "  gap_start = gap['start']\n",
        "  gap_end = gap['end']\n",
        "  subscription_first_events_nogaps = subscription_first_events_nogaps[~((subscription_first_events_nogaps.date >= gap_start) & (subscription_first_events_nogaps.date <= gap_end))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "0RSJuqvnvMQy",
        "outputId": "18429b99-7b56-4f4b-86de-c86d4ccd7d98"
      },
      "outputs": [],
      "source": [
        "# get new member yearly count based only on subscriptions\n",
        "# newmember_subscriptions_by_year = subscription_first_events.groupby([pd.Grouper(key='date', freq='Y')])['member_id'].count().reset_index()\n",
        "\n",
        "newmember_subscriptions_by_year = subscription_first_events_nogaps.groupby([pd.Grouper(key='date', freq='Y')])['member_id'].count().reset_index()\n",
        "newmember_subscriptions_by_year.rename(columns={'member_id': 'total'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S2JKxMgxvOAE",
        "outputId": "6a0f9a3e-c9a9-4042-b496-d326651d65cc"
      },
      "outputs": [],
      "source": [
        "# get new member monthly count based only on subscriptions, so we can forecast with prophet\n",
        "newmember_subscriptions_by_week = subscription_first_events_nogaps.groupby([pd.Grouper(key='date', freq='W')])['member_id'].count().reset_index()\n",
        "newmember_subscriptions_by_week.rename(columns={'member_id': 'total'}, inplace=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
